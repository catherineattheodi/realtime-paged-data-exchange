<!DOCTYPE html>
<html xmlns='http://www.w3.org/1999/xhtml' lang='en'>
  <head>
    <meta charset='utf-8'/>
    <title>Realtime Paged Data Exchange</title>

    <script type="text/javascript" class='remove'>
        var respecConfig = {
          // specification status (e.g. WD, LCWD, NOTE, etc.). If in doubt use ED.
          specStatus:           "CG-DRAFT",

          // the specification's short name, as in http://www.w3.org/TR/short-name/
          shortName:            "realtime-paged-data-exchange",

          // if you wish the publication date to be other than today, set this
          // publishDate:  "2009-08-06",

          // if there is a previously published draft, uncomment this and set its YYYY-MM-DD date
          // and its maturity status
          // previousPublishDate:  "1977-03-15",
          // previousMaturity:  "WD",

          // if there a publicly available Editor's Draft, this is the link
          edDraftURI:           "https://www.openactive.io/realtime-paged-data-exchange/",
          //prevED:  "https://www.openactive.io/spec-template/",
          previousURI:  "https://www.openactive.io/realtime-paged-data-exchange/0.2.3/",
          testSuiteURI: "https://www.openactive.io/endpoint-validator/",
          copyrightStart: 2015,

          // if this is a LCWD, uncomment and set the end of its review period
          // lcEnd: "2009-08-05",

          // editors, add as many as you like
          // only "name" is required
          editors: [
              { name: "Nick Evans", url: "http://nickevans.me/",
                company: "imin", companyURL: "http://www.imin.co/",
                w3cid: "nickevans" },
              { name: "James Smith", url: "http://floppy.org.uk",
                company: "Open Data Institute", companyURL: "http://opendata.institute/" }

          ],

          // authors, add as many as you like.
          // This is optional, uncomment if you have authors as well as editors.
          // only "name" is required. Same format as editors.

          authors: [
          ],

          otherLinks: [{
                key: "Repo",
                value: "We are on Github",
                href: "https://github.com/openactive/realtime-paged-data-exchange/",
                class: "repo"
            }, {
                key: "Issues",
                href: "https://github.com/openactive/realtime-paged-data-exchange/issues/"
            }, {
                key: "Version",
                value: "Editor's Draft"
            }, {
                key: "Previous Version",
                data: [
                    {
                        value: "0.2.3",
                        href: "https://www.openactive.io/realtime-paged-data-exchange/0.2.3/"
                    }
                ]
            }
          ],

          logos: [
            {
              src: 'https://www.openactive.io/assets/openactive-logo-large.png',
              href: "https://www.openactive.io",
              alt: "openactive.io",
              width: 255, //170
              height: 43, //22
              id: 'logo'
            }
          ],

          // extend the bibliography entries
          //localBiblio: {},

          // name of the WG
          wg:           "Openactive Community Group",

          // URI of the public WG page
          wgURI:        "http://www.w3.org/community/openactive/",

          // name (with the @w3c.org) of the public mailing to which comments are due
          wgPublicList: "public-openactive",

          // URI of the patent status for this WG, for Rec-track documents
          // !!!! IMPORTANT !!!!
          // This is important for Rec-track documents, do not copy a patent URI from a random
          // document unless you know what you're doing. If in doubt ask your friendly neighbourhood
          // Team Contact.
          wgPatentURI:  "",
          maxTocLevel: 4,
          preProcess: [ ] ,
          alternateFormats: [ {uri: "diff-previous.html", label: "diff to previous version"} ],
          isRecTrack:   true,
          isNoTrack:    true,
          issueBase:    "https://github.com/openactive/realtime-paged-data-exchange/issues/",
          format: "markdown",
          localBiblio: {
            "Modelling-Opportunity-Data": {
                "href": "https://www.openactive.io/modelling-opportunity-data/",
                "title": "Modelling Opportunity Data",
                "publisher": "Open Active Community Group",            
            },
            "SCHEMA-ORG": {
                "href": "http://schema.org/",
                "title": "Schema.org"
                
            },
            "Publishing-Opportunity-Data": {
                "href": "https://www.openactive.io/opportunity-data-primer/",
                "title": "Publishing Opportunity Data: A Primer",
                "publisher": "Open Active Community Group",            
            }                                  
          }
        };
    </script>

    <script src='https://www.openactive.io/respec/builds/respec-w3c-common.js' class='remove'></script>

    <!-- <script src='/builds/respec-w3c-common.js' class='remove'></script>-->

    <!-- <script src='/node_modules/requirejs/require.js' data-main='/js/profile-w3c-common' async class='remove'></script> -->

    <style>
    table {border-collapse: collapse; border: 1px solid #bec9d9}
    td, th {padding: 3px 0.5em; border-left:1px solid black; border-right: 1px solid black; border-bottom:1px solid #E2EDFE;}
    tr th[colspan] {color: #005A9C; background-color: #FEEDE2; text-align: center}
    th {color: #005A9C; background-color: #E2EDFE; font-weight: normal;border-bottom:1px solid #BEC9D9;}
    tbody tr th {text-align: left;}
    td.nb { font-size: smaller;}
    .rec, .pr {color: #005A9C; background-color: #99EE99}
    .ext {background-color: #FFFFFF}
    .cr, .lcwd {color: #005A9C; background-color: #EEEE99}
    .wd {color: #005A9C; background-color: #EE9999}
    .ed, .fpwd  {color: #005A9C; background-color: #FF7777}
    code {white-space: pre;}
    </style>

  </head>
  <body >
    <style>
    html {
      background-image: none !important;
    }
    body {
      background: white top left fixed no-repeat !important;
      background-size: 25px auto !important;
      background-image: url('https://www.openactive.io/assets/openactive-label-editorsdraft.png') !important;
    }
    body.toc-sidebar #toc {
      background-attachment: fixed !important;
    }
    h1 {
      font-family: 'Open Sans',sans-serif !important;
      font-weight: 300 !important;
      color: #69b9ff !important;
      font-size: 220%;
    }
    #toc {
      padding-top: 0px !important;
    }
    </style>

    <section id='abstract'>

        This specification tackles the generic use-case of unidirectional real-time data synchronisation between two systems, where the receiving system requires only summary data from the origin system.

    </section>

    <section id='sotd'>
      The purpose of the document is to represent an early draft. It is likely to change, so this document should only be used to guide implementations in conversation with the [Openactive](https://www.openactive.io/) community where the quick win of data sharing and shared learning are high priorities.

      Comments on this document are not only welcomed but are actively solicited and should be made on [GitHub Issues](https://github.com/openactive/realtime-paged-data-exchange/issues). The source code is available on [GitHub](https://github.com/openactive/realtime-paged-data-exchange).
    </section>

    <section class="informative">

    # Introduction

    ## Openactive

    The W3C Openactive Community Group was established with the objective of facilitating the sharing and use of physical activity data. The motivation for that is physical activity data is currently largely closed, and sharing and opening up of this data has enormous potential.

    Openactive specifications are modular, each focussing on a specific use cases regarding physical activity data.

    Other aspects of the Community Group's work includes the collation and specification of test suites to assess conformance to referenced standards, and the specification of a framework within which such conformance testing might be assessed are referenced.

    ## Use case and requirements

    Booking systems contains session data (a specific event at a time in a location). Examples include bookable squash courts, Yoga classes, and running groups.

    ### Realtime
    This session data is frequently updated, as sessions are booked, descriptions changed. The data must be available as close to real-time as possible.

    ### Simplicity of implementation
    Many booking systems are maintained by an agency or supplier, and changes are funded by organisations with a small budgets. Hence simplicity and speed of implementation is paramount.

    ### Flexibility of interface
    Due to the cost of work on the booking system side, this interface must not be a constraint to innovation. Innovators should be able to easily implement novel solutions on top of the data without additional effort on the booking system side. This means ideally pushing all query complexity out of the booking system in order to maximise flexibility, and providing a simple sync.

    ## Scope

    This specification is tightly defined to cover data exchange and synchronisation itself; to cover the real-time exchange of generic entities between two systems.

    ### Goals

    - Sharing of session data, including related metadata (clubs, courses, membership requirements, skill level, cost), and events (e.g. open days).
    - Paging and synchronisation to ensure robust incremental transport of data.
    - Allows a client to "refresh its cache", by providing the facility to download all data.
    - (Stretch goal) Extendable to support real-time, high volume data transfer, to satisfy peak load requirements.


    ### Non-Goals

    - User Authentication.
    - Booking and payment.
    - Availability of courts and facilities.
    - Membership packages.
    - Standardisation of content (e.g. "Football" = "Soccer").


    ## Objectives

    - Easy to understand
    - Simple to implement (does not require complex libraries)
    - Based on existing standards where possible
    - Minimalistic (focus on removing complexity)
    - Minimise traffic between services
    - Robust to errors and failed requests
    - Capable of scaling to handle high volumes

    </section>
    <section id='conformance'>

    This specification describes the conformance criteria for Openactive data synchronisation endpoints.

    </section>

    # Overall approach

    In order to create a simple specification that is robust and scalable, the transport mechanism is separated from the paged exchange specifics. By applying paging to all transport alternatives, the approach is inherently scalable.

    The specification is split into the three labelled elements of <a href='#fig-elements-of-this-specification'></a>.


    <figure>
      ![](images/image02.png)
      <figcaption>Elements of this specification</figcaption>
    </figure>



    # Paging

    A paged approach to [[!JSON]] data exchange is used, requiring minimum traffic for real-time or near-real-time synchronisation.


    ## Simplicity

    The paged [[!JSON]] data exchange standard is incredibly simple to implement, but conceptually requires some explanation.

    ## Core concept

    Consider an ordered list as shown in <a href='#fig-illustration-of-the-deterministic-list'></a>, with the following invariants:

    - A continuous list of records that MUST be sorted deterministically and chronological (in the order they were updated). Either (i) ordered first by modified timestamp, and second by ID or (ii) ordered by an incrementing counter where records are assigned a new unique value on each update.

    - Every record MUST only be represented *once* in this list at a given moment, with its position in the list depending on when it was last updated. Records can freely move position in the list as they are updated.

    - This deterministic ordering based on timestamp allows for pages of arbitrary size to be sent without concern for race conditions; if a record is updated during the transfer of a page it MUST appear on a subsiquent page (i.e. simply reappear further down the list).

    - Pages are defined using a "next page URL", which MUST contain enough information to identify a position in the list (e.g. by a "timestamp" and "ID" combination). It MUST NOT reference a specific record, as that record can change position in the list.

    - If a "next page URL" is not used to access the list, the first page MUST be returned.

    - If the consumer reaches the end of the list they consider themselves up-to-date at that moment, and can frequently revisit the end of the list in order to retrieve further updates.

    <figure>
      ![](images/image00.png)
      <figcaption>Illustration of the deterministic list</figcaption>
    </figure>



    ## Example Implementations

    Two example implementations are described below, both adhere to the specified invariants. One of these two examples SHOULD be used as a basis for any implementation, unless the invariants are well understood and the implementation can be thoroughly tested.


    ### Modified Timestamp and ID

    The content of a [[!JSON]] page which could be defined by two parameters:

    - **afterTimestamp**: the modified timestamp, after which results will be returned (if not specified will return from beginning of time)
    - **afterId**: the ID after which results will be returned (if not specified will return all IDs from the first)


    In this example, `afterTimestamp=1453931925&afterId=12` would return **Page 2** labelled in <a href='#fig-illustration-of-the-deterministic-list'></a>. ence the last record of a returned page of results can be used as parameters to retrieve the next page of results. This paging allows for an ongoing data synchronisation that synchronises all data, which can be replayed arbitrarily by the client.

    Note that the timestamp does not need to reflect actual time, as long as it providers a chronological ordering. An integer, string or other representation is sufficient, provided it is sufficiently comparable to support the invariants.


    For a single entity type (e.g. sessions), the data returned can be defined as follows:

    ```javascript
    var query;
    if (queryParams.from) {
        query = Session.query().filter((Session.modified == queryParams.afterTimestamp && Session.id > queryParams.afterId) || (Session.modified > queryParams.afterTimestamp));
    } else {
        query = Session.query()
    }
    return query.sort([Session.modified, Session.id])
    ```


    ### Incrementing Unique ID

    The content of a [[!JSON]] page could be defined by just one parameter:

    - **afterId**: the ID after which results will be returned (if not specified will return all IDs from the first)


    The ID MUST provide a deterministic chronological ordering within the scope of the endpoint. A database-wide counter is sufficient (such as SQL Server's [timestamp](https://msdn.microsoft.com/en-us/library/ms182776%28v=SQL.90%29.aspx) or [rowversion](https://msdn.microsoft.com/en-GB/library/ms182776.aspx)). The consumer ("System 2") simply maintains the "next page URL", so the detail of the ID is not constrained.


    ## Related entities

    This specification can be implemented for each relevant entity type within System 1 (e.g. club, courses, sessions).

    Data from related entities can either be:

    1. Embedded inside the parent entity. This requires the parent "updated" field to reflect the maximum value of all children - achievable via database triggers or similar.

    1. Provided by separate endpoints implementing this specification, the combination of which can be reassembled by System 2.



    ## Response grammar

    It should be noted that although the `<data>` element is open to conformance with [[JSON-LD]], the paging has been deemed too trivial to require the application of any specific serialization.


    ### `<response>`


    ```JSON
    <response> => {
          items: [<item>,<item>,<item>,...],
          next: "/getSessions?afterTimestamp=<date>&afterId=<id>"
       }
    ```

    A generic response specification is included here, the idea being that we standardise the transport encapsulation for the records (paging and polling logic) across entities and systems so that, we can genericise this logic on both sides.

Key | Description
--- | ---
items | An array of `<item>`, which should simply by empty `[]` if no results are returned.
next | For polling, the "next" URL in the response is a precomputed next URL that would be called by the client to get the next page (which would be polled after a delay if the previous page had returned no data). Note "polling" and "paging" are differentiated only by the duration between requests. Although an example endpoint name is provided, this is outside the scope of this standard.


    ### `<item>`


    ```
    <item> => {
          state: 'updated' | 'deleted', (4)
          kind: "session", (2)
          id: "{21EC2020-3AEA-4069-A2DD-08002B303123}", (6)
          modified: Date(a),
          data: <data> (4)
       }
    ```


Key | Description
--- | ---
state | Deleted items are included in the response with a "deleted" state, but no `<data>` associated.
kind | The "kind" attribute allows for the representation of different entity types. The standard does not advocate embedding of child entities if they change more frequently than the parent. Each entity type ("kind") can be synchronised separately, this allows us to decouple the sync logic from the data structure, and allows us to reassemble the data structure on the client side. It also makes the implementation very simple.
id | Although IDs shown here are GUIDs, and above are numeric, and although the example above shows Unix timestamps, the standard does not prescribe any specific format of either.
modified | Modified timestamp of the item. Must be comparable to itself.
data | Note this key is not included if state is `'deleted'`


    ### `<data>`

    The `<data>` part of the response is open for applications for populate with whatever data structure is most appropriate for the entity type ("kind") being exchanged. 
    
    Applications SHOULD use a standard data model to increase interoperability of the exchanged data. For example an application may choose to use entities and properties defined in [[SCHEMA-ORG]] to help structure data in a useful way for reusers. 
    
    Applications that are exchanging data about entities described in [[Modelling-Opportunity-Data]] SHOULD ensure that their data conforms to that specification. 
    This includes data on Events, Organisations, Places, etc. [[Publishing-Opportunity-Data]] provides additional examples and guidance on using that data model 
    in ways that are compatible with the other standards publishing by OpenActive.
    
    Applications that publish data using bespoke data models SHOULD provide users with relevant documentation.
    
    <div class="note">
    The remainder of this specification uses simple examples when showing `<data>` elements in responses. However these examples are for illustrative purposes only. Read the 
    </div>


    ## Example

    A full example REST response from polling:

    ```
    /getSessions?afterTimestamp=1453931101&afterId={c15814e5-8931-470c-8a16-ef45afedaece}
    -> { items: [
            {
                state: "updated",
                kind: "session",
                id: "{c15814e5-8931-470c-8a16-ef45afedaece}",
                modified: 1453931101,
                data: {
                   lat: 51.5072,
                   lng: -0.1275,
                   name: 'Acrobatics with Dave',
                   clubId: "{fc1f0f87-0538-4b05-96a0-cee88b9c3377}"
                }
            },
            {
                state: "deleted",
                kind: "session",
                id: "{d97f73fb-4718-48ee-a6a9-9c7d717ebd85}",
                modified: 1453931925
            }
          ],
          next: '/getSessions?afterTimestamp=1453931925&afterId={d97f73fb-4718-48ee-a6a9-9c7d717ebd85}'
    }
    ```


    # Transport

    These transport options cover different levels of complexity and data volume. Note that in all cases polling must be implemented to support a full cache refresh and data download. The real-time transport mechanisms work alongside infrequent polling to keep the data current.

    In the case of real time transport failure, a production client implementation can fall back to polling.


    Transport Options              | Advantages                                                                                              | Disadvantages                                                                       | Primary Use Case
    ------------------------------ | ------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------- | --------------------------------------------------------------------------------
    Polling (Simple download)      | Simple to implement                                                                                     | Does not provide a real-time feed, and heuristic polling will result in patchy sync | Full cache refresh (also can be used in isolation for prototype implementation).
    Webhooks (Real-time)           | Less traffic than polling, more server-side control, allows for real-time, uses standard REST interface | Uses many high-latency connections                                                  | Basic production implementation
    Server-Sent Events (Real-time) | Optimisation over webhooks as uses one connection, so can handle higher volume                          | Requires additional libraries                                                       | High volume production implementation
    AMQP (Real-time)               | Pages can be handed off to the queue to facilitate even higher volume than Server-Sent Events           | Requires additional infrastructure                                                  | Very high volume production implementation


    ## Polling

    A basic REST endpoint which accepts the from and after parameters is required to allow a full cache refresh / data download on demand (e.g. `/getSessions?afterTimestamp=Date(b)&afterId={d97f73fb}`).

    For cases where only a polling endpoint is available, the client will poll the endpoint using heuristic backoff.

    Implementation of at least one other type of endpoint is recommended in order to enable real-time updates.


    ## Webhooks

    Webhooks use the same mechanism as polling, except that pages are pushed from server to client, rather than requested explicitly by the client from the server.

    The client registers an endpoint with the server, and the server repeatedly sends subsequent pages to the client. Using the same paging features as with polling allows the server to batch items to increase throughput.

    When sending a particular page to the client the server is expected to wait for a successful acknowledgement of the page before sending the next page. If sending of a page fails that page should be continuously retried with an exponential backoff. The server should only proceed to the following page after successfully sending the previous one.

    Note that during a full cache refresh the client will page the server for all data, and may simultaneously be receiving webhook requests from the client. Using the timestamp of each record to ensure records are only updated with newer data, the client is able to perform both the full cache refresh and receive webhook requests simultaneously. Alternatively the client can choose to drop webhook requests until its full cache refresh is complete, which should trigger the exponential backoff behaviour from the server, ensuring a good crossover in items between the end of the cache refresh and the webhook updates resuming.


    ### Webhooks Example

    Example payload for the webhook:

    ```
    /putSessions
    -> { items: [{
           state: 'updated',
           kind: "session",
           id: "{c15814e5-8931-470c-8a16-ef45afedaece}",
           modified: Date(a),
           data: {
               lat: 51.5072,
               lng: -0.1275,
               name: 'Acrobatics with Dave',
               clubId: "{fc1f0f87-0538-4b05-96a0-cee88b9c3377}"
           }
        },{
           state: 'deleted',
           kind: "session",
           id: "{d97f73fb-4718-48ee-a6a9-9c7d717ebd85}",
           modified: Date(b)
        }]
    }
    ```

    Note that the "next" from the response is not required here. Instead, from and after should be stored for each client of the server, in order that the server is able to send the relevant next page to each client.


    ## Server-Sent Events ([[!eventsource]])

    [Server-Sent Events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events) ([[!eventsource]]) (over HTTPS) provides a simple and efficient channel through which a high volume of updates can pass. Although an additional library may be required depending on the servers' platform, it is a very light implementation.

    Server-Sent Events require System 1 to implement a system to keep track of events and trigger the sending of data through this channel. This non-trivial implementation, together with the complexities of library support in various languages and frameworks compared with a straightforward [[!JSON]] API implementation used in Polling and Webhooks is the reason that the other transport mechanisms are provided.

    The responsibility is on the client to reestablish a connection to the server and inform it of the last retrieved record in order to continue the stream, which is closer to polling than to webhooks.

    Response grammar / example:

    ```
    /stream?afterTimestamp=Date(b)&afterId={d97f73fb-4718-48ee-a6a9-9c7d717ebd85}
    ->
    event: itemupdate
    data: <item>
    ```

    Only the `<item>` from the `<response>` is required here, and is passed as "data" (the Server-Sent Event specification of "data", which is different from the "data" part of the item). The explicit paging used with polling and webhooks is made redundant as this is a continuous stream over one connection.

    The event type is always set to "itemupdate", as the state of each item is set with the "state" field consistent with polling.


    ### Server-Sent Events Example

    An example stream is below:

    ```
    /stream?afterTimestamp=Date(a)&afterId={a97f73fb-4718-48ee-a6a9-9c7d717ebd85}
    ->
    event: itemupdate
    data: {
       state: 'updated',
       kind: "session",
       id: "{c15814e5-8931-470c-8a16-ef45afedaece}",
       modified: Date(a),
       data: {
           lat: 51.5072,
           lng: -0.1275,
           name: 'Acrobatics with Dave',
           clubId: "{fc1f0f87-0538-4b05-96a0-cee88b9c3377}"
       }

    event: itemupdate
    data: {
       state: 'deleted',
       kind: "session",
       id: "{d97f73fb-4718-48ee-a6a9-9c7d717ebd85}",
       modified: Date(b)
    }
    ```


    ## AMQP

    [[OASIS AMQP]](http://www.amqp.org/) (RabbitMQ et. al.) provides a two way channel for events which includes buffering and multiple connections to increase throughput.

    As with Server-sent events, only the `<item>` from the `<response>` is required to be sent in the message, as AMQP makes the explicit paging redundant.

    For very high volumes, this allows the server to send multiple pages in parallel, as it can calculate the "afterTimestamp" and "afterId" parameter and control the send. The client can also process these in parallel (particularly useful in the case of shared or No-SQL data stores, with scaling queue processors), using the timestamp of each record to ensure records are only updated with newer data.
    However this requires additional infrastructure and the use of certificates (more complex to configure than HTTPS).



    <section class="informative">

    # Implementation

    Three common patterns of implementation are presented, along with specific advantages and disadvantages of each, together with miscellaneous notes.

    ## Single JSON entity cache table

    Create a cache table which is written to on each entity change (or related entity change, if a calculated field is created), either via an application or database trigger (which can also be used to trigger the webhook). The table contains the rendered [[!JSON]] `<item>`, along with the modified timestamp and the ID.

    Entries in the table overwrite old items with a newer modified timestamp.

    This table can be easily parsed into output for the client. This has the advantage of allowing one endpoint and one process to manage the real-time sync by watching this single table, as the table can maintain a sort and page across all entity "kinds".


    ## Multiple table on-demand JSON generation

    The [[!JSON]] is generated from each table individually at the point that is requested by either the webhook or poll.

    An endpoint will be required for each entity "kind", as the sort cannot efficiently happen across tables. These endpoints would require separate webhook / polling processes to keep them in sync (though the webhooks can all share the same endpoint on the client).


    ## Hybrid approach: paging table

    A paging table could be created that contains only the Kind, Modified Timestamp and ID. This table is then updated with each entity update, however the [[!JSON]] is only generated on-demand by getting the next page from the paging table and rendering [[!JSON]] for each of IDs of the "kinds" returned.


    ## Additional notes

    ### Calculated fields (e.g. available spaces or available tickets for a session)

    As some entities will not need to be synchronised, but fields calculated from them will need to be known to the client (e.g. the "tickets" table may not need to be synchronised, but the "available tickets" calculated field on the "sessions" table will be required).

    The suggested approach is to calculate the field "available tickets" and store it in the "sessions" table on each ticket sale. This has three advantages:

    - It keeps the application logic for such calculation together with the original action.
    - It creates a cached value that can be used in other parts of the application to increase performance.
    - It prevents the creation of complex calculations which are used only on-demand for the purposes of data synchronisation.

    An alternative could be to calculate it on each synchronisation, however this will slow down the sync. Assuming that reads will occur on this calculated data more frequently than writes, caching the calculated field is recommended.


    ### Strict ordering of items

    For high-throughput AMQP, when updating data in the client's index, the timestamp of each record will be used to ensure records are only updated with newest data. Although this technique can be used specifically for AMQP, all other methods of transport must adhere to a strict ordering of items by modified timestamp and ID (per kind) in order to ensure data consistency. Ordering between kinds is not important.


    ### Database Triggers (MS SQL Server example)

    If using a
     [timestamp](https://msdn.microsoft.com/en-us/library/ms182776%28v=SQL.90%29.aspx)/[rowversion](https://msdn.microsoft.com/en-GB/library/ms182776.aspx) field on the parent table as the "modified timestamp", using the trigger below for each child table will update the rowversion field in the relevant rows on the parent table when the child table is updated.

    The `SET SomeColumn = SomeColumn` part of this trigger could easily be replaced with setting materialised calculated fields (e.g. "total number of tickets sold") which contain the summary data required by "System 2". This reduces the need to join the child table during the API endpoint response, which helps to optimise the endpoint.

    The example below has been adapted from [here](http://stackoverflow.com/questions/2165333/how-to-update-sql-server-timestamp-column-without-changing-record-data), see [here](https://msdn.microsoft.com/en-us/library/ms191300.aspx) for an explanation of the mechanics.

    ```
    CREATE TRIGGER tgUpdateParentRowVersion ON ChildTable FOR INSERT, DELETE, UPDATE
    AS
    BEGIN
       /*
        * The updates below force the update of the parent table rowversion
        */

       /* Materialised field calculation goes here*/

       UPDATE ParentTable
          SET SomeColumn = SomeColumn
         FROM ParentTable a
         JOIN inserted    i on a.pkParentTable = i.fkParentTable

       UPDATE ParentTable
          SET SomeColumn = SomeColumn
         FROM ParentTable a
         JOIN deleted     d on a.pkParentTable = d.fkParentTable
    END

    ```
    </section>

    <section class='appendix informative'>
    Acknowledgements
    ================

    The editors thank [all members](http://www.w3.org/community/openactive/participants) of the Openactive CG for contributions of various kinds.
    </section>
  </body>
</html>
